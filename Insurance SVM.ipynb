{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88112d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28b1adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('aug_train.csv')\n",
    "test_data = pd.read_csv('aug_test.csv')\n",
    "y_test = np.load('answer.npy')\n",
    "train_samples = len(train_data)\n",
    "test_samples = len(test_data)\n",
    "#print(train_samples, test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57d98dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167647</td>\n",
       "      <td>Male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17163</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>43327.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>135</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32023</td>\n",
       "      <td>Female</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>35841.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>253</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87447</td>\n",
       "      <td>Female</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>27645.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>69</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>501933</td>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>29023.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>211</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78268</th>\n",
       "      <td>847</td>\n",
       "      <td>Male</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78269</th>\n",
       "      <td>417524</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>32937.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>185</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78270</th>\n",
       "      <td>188087</td>\n",
       "      <td>Male</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>35247.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78271</th>\n",
       "      <td>215680</td>\n",
       "      <td>Male</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>25705.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>86</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78272</th>\n",
       "      <td>138006</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>27752.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>235</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460427 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  Gender  Age  Driving_License  Region_Code  Previously_Insured  \\\n",
       "0      167647    Male   22                1          7.0                   1   \n",
       "1       17163    Male   42                1         28.0                   0   \n",
       "2       32023  Female   66                1         33.0                   0   \n",
       "3       87447  Female   22                1         33.0                   0   \n",
       "4      501933    Male   28                1         46.0                   1   \n",
       "...       ...     ...  ...              ...          ...                 ...   \n",
       "78268     847    Male   43                1         39.0                   0   \n",
       "78269  417524  Female   21                1         12.0                   1   \n",
       "78270  188087    Male   48                1         29.0                   1   \n",
       "78271  215680    Male   64                1          5.0                   1   \n",
       "78272  138006  Female   25                1         41.0                   1   \n",
       "\n",
       "      Vehicle_Age Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  \\\n",
       "0        < 1 Year             No          2630.0                 152.0   \n",
       "1        1-2 Year            Yes         43327.0                  26.0   \n",
       "2        1-2 Year            Yes         35841.0                 124.0   \n",
       "3        < 1 Year             No         27645.0                 152.0   \n",
       "4        < 1 Year             No         29023.0                 152.0   \n",
       "...           ...            ...             ...                   ...   \n",
       "78268    1-2 Year            Yes          2630.0                 124.0   \n",
       "78269    < 1 Year             No         32937.0                 152.0   \n",
       "78270    1-2 Year             No         35247.0                 124.0   \n",
       "78271    1-2 Year             No         25705.0                  26.0   \n",
       "78272    < 1 Year             No         27752.0                 152.0   \n",
       "\n",
       "       Vintage  Response  \n",
       "0           16       0.0  \n",
       "1          135       0.0  \n",
       "2          253       0.0  \n",
       "3           69       0.0  \n",
       "4          211       0.0  \n",
       "...        ...       ...  \n",
       "78268       26       NaN  \n",
       "78269      185       NaN  \n",
       "78270      101       NaN  \n",
       "78271       86       NaN  \n",
       "78272      235       NaN  \n",
       "\n",
       "[460427 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([train_data, test_data])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b714bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Region_Code_0.0</th>\n",
       "      <th>...</th>\n",
       "      <th>Policy_Sales_Channel_152.0</th>\n",
       "      <th>Policy_Sales_Channel_153.0</th>\n",
       "      <th>Policy_Sales_Channel_154.0</th>\n",
       "      <th>Policy_Sales_Channel_155.0</th>\n",
       "      <th>Policy_Sales_Channel_156.0</th>\n",
       "      <th>Policy_Sales_Channel_157.0</th>\n",
       "      <th>Policy_Sales_Channel_158.0</th>\n",
       "      <th>Policy_Sales_Channel_159.0</th>\n",
       "      <th>Policy_Sales_Channel_160.0</th>\n",
       "      <th>Policy_Sales_Channel_163.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167647</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17163</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43327.0</td>\n",
       "      <td>135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32023</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35841.0</td>\n",
       "      <td>253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87447</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27645.0</td>\n",
       "      <td>69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>501933</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29023.0</td>\n",
       "      <td>211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78268</th>\n",
       "      <td>847</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78269</th>\n",
       "      <td>417524</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32937.0</td>\n",
       "      <td>185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78270</th>\n",
       "      <td>188087</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35247.0</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78271</th>\n",
       "      <td>215680</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25705.0</td>\n",
       "      <td>86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78272</th>\n",
       "      <td>138006</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27752.0</td>\n",
       "      <td>235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460427 rows × 223 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  Age  Driving_License  Previously_Insured  Annual_Premium  \\\n",
       "0      167647   22                1                   1          2630.0   \n",
       "1       17163   42                1                   0         43327.0   \n",
       "2       32023   66                1                   0         35841.0   \n",
       "3       87447   22                1                   0         27645.0   \n",
       "4      501933   28                1                   1         29023.0   \n",
       "...       ...  ...              ...                 ...             ...   \n",
       "78268     847   43                1                   0          2630.0   \n",
       "78269  417524   21                1                   1         32937.0   \n",
       "78270  188087   48                1                   1         35247.0   \n",
       "78271  215680   64                1                   1         25705.0   \n",
       "78272  138006   25                1                   1         27752.0   \n",
       "\n",
       "       Vintage  Response  Gender_Female  Gender_Male  Region_Code_0.0  ...  \\\n",
       "0           16       0.0              0            1                0  ...   \n",
       "1          135       0.0              0            1                0  ...   \n",
       "2          253       0.0              1            0                0  ...   \n",
       "3           69       0.0              1            0                0  ...   \n",
       "4          211       0.0              0            1                0  ...   \n",
       "...        ...       ...            ...          ...              ...  ...   \n",
       "78268       26       NaN              0            1                0  ...   \n",
       "78269      185       NaN              1            0                0  ...   \n",
       "78270      101       NaN              0            1                0  ...   \n",
       "78271       86       NaN              0            1                0  ...   \n",
       "78272      235       NaN              1            0                0  ...   \n",
       "\n",
       "       Policy_Sales_Channel_152.0  Policy_Sales_Channel_153.0  \\\n",
       "0                               1                           0   \n",
       "1                               0                           0   \n",
       "2                               0                           0   \n",
       "3                               1                           0   \n",
       "4                               1                           0   \n",
       "...                           ...                         ...   \n",
       "78268                           0                           0   \n",
       "78269                           1                           0   \n",
       "78270                           0                           0   \n",
       "78271                           0                           0   \n",
       "78272                           1                           0   \n",
       "\n",
       "       Policy_Sales_Channel_154.0  Policy_Sales_Channel_155.0  \\\n",
       "0                               0                           0   \n",
       "1                               0                           0   \n",
       "2                               0                           0   \n",
       "3                               0                           0   \n",
       "4                               0                           0   \n",
       "...                           ...                         ...   \n",
       "78268                           0                           0   \n",
       "78269                           0                           0   \n",
       "78270                           0                           0   \n",
       "78271                           0                           0   \n",
       "78272                           0                           0   \n",
       "\n",
       "       Policy_Sales_Channel_156.0  Policy_Sales_Channel_157.0  \\\n",
       "0                               0                           0   \n",
       "1                               0                           0   \n",
       "2                               0                           0   \n",
       "3                               0                           0   \n",
       "4                               0                           0   \n",
       "...                           ...                         ...   \n",
       "78268                           0                           0   \n",
       "78269                           0                           0   \n",
       "78270                           0                           0   \n",
       "78271                           0                           0   \n",
       "78272                           0                           0   \n",
       "\n",
       "       Policy_Sales_Channel_158.0  Policy_Sales_Channel_159.0  \\\n",
       "0                               0                           0   \n",
       "1                               0                           0   \n",
       "2                               0                           0   \n",
       "3                               0                           0   \n",
       "4                               0                           0   \n",
       "...                           ...                         ...   \n",
       "78268                           0                           0   \n",
       "78269                           0                           0   \n",
       "78270                           0                           0   \n",
       "78271                           0                           0   \n",
       "78272                           0                           0   \n",
       "\n",
       "       Policy_Sales_Channel_160.0  Policy_Sales_Channel_163.0  \n",
       "0                               0                           0  \n",
       "1                               0                           0  \n",
       "2                               0                           0  \n",
       "3                               0                           0  \n",
       "4                               0                           0  \n",
       "...                           ...                         ...  \n",
       "78268                           0                           0  \n",
       "78269                           0                           0  \n",
       "78270                           0                           0  \n",
       "78271                           0                           0  \n",
       "78272                           0                           0  \n",
       "\n",
       "[460427 rows x 223 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.get_dummies(data, columns=['Gender', 'Region_Code', 'Vehicle_Age', 'Vehicle_Damage', 'Policy_Sales_Channel'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9382b500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Response</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Region_Code_0.0</th>\n",
       "      <th>...</th>\n",
       "      <th>Policy_Sales_Channel_152.0</th>\n",
       "      <th>Policy_Sales_Channel_153.0</th>\n",
       "      <th>Policy_Sales_Channel_154.0</th>\n",
       "      <th>Policy_Sales_Channel_155.0</th>\n",
       "      <th>Policy_Sales_Channel_156.0</th>\n",
       "      <th>Policy_Sales_Channel_157.0</th>\n",
       "      <th>Policy_Sales_Channel_158.0</th>\n",
       "      <th>Policy_Sales_Channel_159.0</th>\n",
       "      <th>Policy_Sales_Channel_160.0</th>\n",
       "      <th>Policy_Sales_Channel_163.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167647</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17163</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43327.0</td>\n",
       "      <td>135</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32023</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35841.0</td>\n",
       "      <td>253</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87447</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27645.0</td>\n",
       "      <td>69</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>501933</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29023.0</td>\n",
       "      <td>211</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78268</th>\n",
       "      <td>847</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78269</th>\n",
       "      <td>417524</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32937.0</td>\n",
       "      <td>185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78270</th>\n",
       "      <td>188087</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35247.0</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78271</th>\n",
       "      <td>215680</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25705.0</td>\n",
       "      <td>86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78272</th>\n",
       "      <td>138006</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27752.0</td>\n",
       "      <td>235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460427 rows × 223 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  Age  Driving_License  Previously_Insured  Annual_Premium  \\\n",
       "0      167647   22                1                   1          2630.0   \n",
       "1       17163   42                1                   0         43327.0   \n",
       "2       32023   66                1                   0         35841.0   \n",
       "3       87447   22                1                   0         27645.0   \n",
       "4      501933   28                1                   1         29023.0   \n",
       "...       ...  ...              ...                 ...             ...   \n",
       "78268     847   43                1                   0          2630.0   \n",
       "78269  417524   21                1                   1         32937.0   \n",
       "78270  188087   48                1                   1         35247.0   \n",
       "78271  215680   64                1                   1         25705.0   \n",
       "78272  138006   25                1                   1         27752.0   \n",
       "\n",
       "       Vintage  Response  Gender_Female  Gender_Male  Region_Code_0.0  ...  \\\n",
       "0           16      -1.0              0            1                0  ...   \n",
       "1          135      -1.0              0            1                0  ...   \n",
       "2          253      -1.0              1            0                0  ...   \n",
       "3           69      -1.0              1            0                0  ...   \n",
       "4          211      -1.0              0            1                0  ...   \n",
       "...        ...       ...            ...          ...              ...  ...   \n",
       "78268       26       NaN              0            1                0  ...   \n",
       "78269      185       NaN              1            0                0  ...   \n",
       "78270      101       NaN              0            1                0  ...   \n",
       "78271       86       NaN              0            1                0  ...   \n",
       "78272      235       NaN              1            0                0  ...   \n",
       "\n",
       "       Policy_Sales_Channel_152.0  Policy_Sales_Channel_153.0  \\\n",
       "0                               1                           0   \n",
       "1                               0                           0   \n",
       "2                               0                           0   \n",
       "3                               1                           0   \n",
       "4                               1                           0   \n",
       "...                           ...                         ...   \n",
       "78268                           0                           0   \n",
       "78269                           1                           0   \n",
       "78270                           0                           0   \n",
       "78271                           0                           0   \n",
       "78272                           1                           0   \n",
       "\n",
       "       Policy_Sales_Channel_154.0  Policy_Sales_Channel_155.0  \\\n",
       "0                               0                           0   \n",
       "1                               0                           0   \n",
       "2                               0                           0   \n",
       "3                               0                           0   \n",
       "4                               0                           0   \n",
       "...                           ...                         ...   \n",
       "78268                           0                           0   \n",
       "78269                           0                           0   \n",
       "78270                           0                           0   \n",
       "78271                           0                           0   \n",
       "78272                           0                           0   \n",
       "\n",
       "       Policy_Sales_Channel_156.0  Policy_Sales_Channel_157.0  \\\n",
       "0                               0                           0   \n",
       "1                               0                           0   \n",
       "2                               0                           0   \n",
       "3                               0                           0   \n",
       "4                               0                           0   \n",
       "...                           ...                         ...   \n",
       "78268                           0                           0   \n",
       "78269                           0                           0   \n",
       "78270                           0                           0   \n",
       "78271                           0                           0   \n",
       "78272                           0                           0   \n",
       "\n",
       "       Policy_Sales_Channel_158.0  Policy_Sales_Channel_159.0  \\\n",
       "0                               0                           0   \n",
       "1                               0                           0   \n",
       "2                               0                           0   \n",
       "3                               0                           0   \n",
       "4                               0                           0   \n",
       "...                           ...                         ...   \n",
       "78268                           0                           0   \n",
       "78269                           0                           0   \n",
       "78270                           0                           0   \n",
       "78271                           0                           0   \n",
       "78272                           0                           0   \n",
       "\n",
       "       Policy_Sales_Channel_160.0  Policy_Sales_Channel_163.0  \n",
       "0                               0                           0  \n",
       "1                               0                           0  \n",
       "2                               0                           0  \n",
       "3                               0                           0  \n",
       "4                               0                           0  \n",
       "...                           ...                         ...  \n",
       "78268                           0                           0  \n",
       "78269                           0                           0  \n",
       "78270                           0                           0  \n",
       "78271                           0                           0  \n",
       "78272                           0                           0  \n",
       "\n",
       "[460427 rows x 223 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['Response'] == 0, 'Response'] = -1 # changing negative class to -1 for SVM to work\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cac700e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.iloc[0:train_samples]\n",
    "test_data = data.iloc[train_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b12b6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Region_Code_0.0</th>\n",
       "      <th>Region_Code_1.0</th>\n",
       "      <th>...</th>\n",
       "      <th>Policy_Sales_Channel_152.0</th>\n",
       "      <th>Policy_Sales_Channel_153.0</th>\n",
       "      <th>Policy_Sales_Channel_154.0</th>\n",
       "      <th>Policy_Sales_Channel_155.0</th>\n",
       "      <th>Policy_Sales_Channel_156.0</th>\n",
       "      <th>Policy_Sales_Channel_157.0</th>\n",
       "      <th>Policy_Sales_Channel_158.0</th>\n",
       "      <th>Policy_Sales_Channel_159.0</th>\n",
       "      <th>Policy_Sales_Channel_160.0</th>\n",
       "      <th>Policy_Sales_Channel_163.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57782</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38244.0</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>286811</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37577.0</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>117823</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24578.0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>213992</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40507.0</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>324756</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36783.0</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78268</th>\n",
       "      <td>847</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78269</th>\n",
       "      <td>417524</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32937.0</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78270</th>\n",
       "      <td>188087</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35247.0</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78271</th>\n",
       "      <td>215680</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25705.0</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78272</th>\n",
       "      <td>138006</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27752.0</td>\n",
       "      <td>235</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78273 rows × 222 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  Age  Driving_License  Previously_Insured  Annual_Premium  \\\n",
       "0       57782   34                1                   1         38244.0   \n",
       "1      286811   55                1                   0         37577.0   \n",
       "2      117823   39                1                   1         24578.0   \n",
       "3      213992   28                1                   1         40507.0   \n",
       "4      324756   24                1                   0         36783.0   \n",
       "...       ...  ...              ...                 ...             ...   \n",
       "78268     847   43                1                   0          2630.0   \n",
       "78269  417524   21                1                   1         32937.0   \n",
       "78270  188087   48                1                   1         35247.0   \n",
       "78271  215680   64                1                   1         25705.0   \n",
       "78272  138006   25                1                   1         27752.0   \n",
       "\n",
       "       Vintage  Gender_Female  Gender_Male  Region_Code_0.0  Region_Code_1.0  \\\n",
       "0          146              1            0                0                0   \n",
       "1          109              1            0                0                0   \n",
       "2           63              0            1                0                0   \n",
       "3          129              0            1                0                0   \n",
       "4          201              1            0                0                0   \n",
       "...        ...            ...          ...              ...              ...   \n",
       "78268       26              0            1                0                0   \n",
       "78269      185              1            0                0                0   \n",
       "78270      101              0            1                0                0   \n",
       "78271       86              0            1                0                0   \n",
       "78272      235              1            0                0                0   \n",
       "\n",
       "       ...  Policy_Sales_Channel_152.0  Policy_Sales_Channel_153.0  \\\n",
       "0      ...                           0                           0   \n",
       "1      ...                           0                           0   \n",
       "2      ...                           0                           0   \n",
       "3      ...                           0                           0   \n",
       "4      ...                           1                           0   \n",
       "...    ...                         ...                         ...   \n",
       "78268  ...                           0                           0   \n",
       "78269  ...                           1                           0   \n",
       "78270  ...                           0                           0   \n",
       "78271  ...                           0                           0   \n",
       "78272  ...                           1                           0   \n",
       "\n",
       "       Policy_Sales_Channel_154.0  Policy_Sales_Channel_155.0  \\\n",
       "0                               0                           0   \n",
       "1                               0                           0   \n",
       "2                               0                           0   \n",
       "3                               0                           0   \n",
       "4                               0                           0   \n",
       "...                           ...                         ...   \n",
       "78268                           0                           0   \n",
       "78269                           0                           0   \n",
       "78270                           0                           0   \n",
       "78271                           0                           0   \n",
       "78272                           0                           0   \n",
       "\n",
       "       Policy_Sales_Channel_156.0  Policy_Sales_Channel_157.0  \\\n",
       "0                               0                           0   \n",
       "1                               0                           0   \n",
       "2                               0                           0   \n",
       "3                               0                           0   \n",
       "4                               0                           0   \n",
       "...                           ...                         ...   \n",
       "78268                           0                           0   \n",
       "78269                           0                           0   \n",
       "78270                           0                           0   \n",
       "78271                           0                           0   \n",
       "78272                           0                           0   \n",
       "\n",
       "       Policy_Sales_Channel_158.0  Policy_Sales_Channel_159.0  \\\n",
       "0                               0                           0   \n",
       "1                               0                           0   \n",
       "2                               0                           0   \n",
       "3                               0                           0   \n",
       "4                               0                           0   \n",
       "...                           ...                         ...   \n",
       "78268                           0                           0   \n",
       "78269                           0                           0   \n",
       "78270                           0                           0   \n",
       "78271                           0                           0   \n",
       "78272                           0                           0   \n",
       "\n",
       "       Policy_Sales_Channel_160.0  Policy_Sales_Channel_163.0  \n",
       "0                               0                           0  \n",
       "1                               0                           0  \n",
       "2                               0                           0  \n",
       "3                               0                           0  \n",
       "4                               0                           0  \n",
       "...                           ...                         ...  \n",
       "78268                           0                           0  \n",
       "78269                           0                           0  \n",
       "78270                           0                           0  \n",
       "78271                           0                           0  \n",
       "78272                           0                           0  \n",
       "\n",
       "[78273 rows x 222 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_data.drop('Response', axis=1)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a06ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove id attribute since as it is irrelevant for training\n",
    "train_data = train_data.drop('id', axis=1)\n",
    "test_data = test_data.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c6a56d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop('Response', axis=1)\n",
    "y_train = train_data['Response']\n",
    "X_test = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23b253b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to np arrays to be able to use training functions\n",
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "X_test = X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "262d5907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric: choice of evaluation metric (f1, precision, recall, etc.)\n",
    "# Proportion: proportion of test set to predict as 1s, if needed (logistic regression may predict all 0 by default)\n",
    "def my_cross_val_imbalanced(model, metric, proportion, X, y, k=10):\n",
    "    (n, d) = X.shape\n",
    "    validation_metrics = np.zeros(k)\n",
    "    for i in range(k):\n",
    "        val_set = X[round(i*n/k):round((i+1)*n/k), :]\n",
    "        val_labels = y[round(i*n/k):round((i+1)*n/k)]\n",
    "        train_set = np.delete(X, [j for j in range(round(i*n/k), round((i+1)*n/k))], 0)\n",
    "        train_labels = np.delete(y, [j for j in range(round(i*n/k), round((i+1)*n/k))], 0)\n",
    "        model.fit(train_set, train_labels)\n",
    "        if proportion == None:\n",
    "            y_preds = model.predict(val_set)\n",
    "        else:\n",
    "            y_preds = model.predict_proportion(val_set, proportion)\n",
    "        \n",
    "        tp, fp, tn, fn = 0, 0, 0, 0\n",
    "        score = 0\n",
    "        for j in range(len(y_preds)):\n",
    "            if val_labels[j] == 1 and y_preds[j] == 1:\n",
    "                tp += 1\n",
    "            elif val_labels[j] == 1:\n",
    "                fn += 1\n",
    "            elif y_preds[j] == 1:\n",
    "                fp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "        if tp == 0: # to avoid division by zero error for trivial models\n",
    "            precision = 0\n",
    "            recall = 0\n",
    "        else:\n",
    "            precision = tp / (tp + fp)\n",
    "            recall = tp / (tp + fn)  \n",
    "        if metric == 'precision':\n",
    "            score = precision\n",
    "        if metric == 'recall':\n",
    "            score = recall\n",
    "        if metric == 'f1':\n",
    "            if precision + recall == 0:\n",
    "                score = 0\n",
    "            else:\n",
    "                score = 2 * precision * recall / (precision + recall)\n",
    "        if metric == 'auprc':\n",
    "            score = sklearn.metrics.average_precision_score(val_labels, y_preds)\n",
    "        validation_metrics[i] = score\n",
    "    return validation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97c7e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_f1(preds, truth):\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for j in range(len(preds)):\n",
    "        if truth[j] == 1 and preds[j] == 1:\n",
    "            tp += 1\n",
    "        elif truth[j] == 1:\n",
    "            fn += 1\n",
    "        elif preds[j] == 1:\n",
    "            fp += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "    if tp + fp > 0:\n",
    "        precision = tp / (tp + fp)\n",
    "    else:\n",
    "        precision = 0\n",
    "    recall = tp / (tp + fn)\n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * precision * recall / (precision + recall)\n",
    "    else: \n",
    "        f1 = 0\n",
    "    return (precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e1a9e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySVM:\n",
    "\n",
    "    def __init__(self, d, max_iters, eta_val, c):\n",
    "        self.w = np.zeros(d)\n",
    "        self.w_old = np.random.uniform(-0.01, 0.01, d)\n",
    "        self.w_sum = np.zeros(d)\n",
    "        self.w_sum += self.w_old\n",
    "        self.max_iters = max_iters\n",
    "        self.eta_val = eta_val\n",
    "        self.c = c\n",
    "        self.iters = 0\n",
    "        self.losses = []\n",
    "        self.gradient_magnitudes = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        (n, d) = X.shape\n",
    "        while self.iters < self.max_iters:\n",
    "            i = np.random.randint(n)\n",
    "            # compute loss; maybe modify for weighted?\n",
    "            loss = (1/2)*np.linalg.norm(self.w_old)**2 + self.c*max(0, 1 - y[i]*(self.w_old @ X[i, :]))\n",
    "            self.losses.append(loss)\n",
    "            gradient_magnitude = 0\n",
    "            for j in range(d):\n",
    "                if y[i]*(self.w_old @ X[i, :]) < 1:\n",
    "                    self.w[j] = self.w_old[j] - self.eta_val*(self.w_old[j] - self.c*y[i]*X[i,j])\n",
    "                    gradient_magnitude += (self.w_old[j] - self.c*y[i]*X[i,j])**2\n",
    "                else:\n",
    "                    self.w[j] = self.w_old[j] - self.eta_val*(self.w_old[j])\n",
    "                    gradient_magnitude += (self.w_old[j])**2\n",
    "                self.w_old[j] = self.w[j]\n",
    "            self.gradient_magnitudes.append(gradient_magnitude)\n",
    "            self.w_sum += self.w\n",
    "            self.iters += 1\n",
    "            if np.average(self.gradient_magnitudes[-10:]) < 1e-6:\n",
    "                break\n",
    "\n",
    "    def predict(self, X):\n",
    "        w_avg = self.w_sum / self.iters\n",
    "        return np.sign(X @ w_avg)\n",
    "    \n",
    "    def predict_values(self, X):\n",
    "        w_avg = self.w_sum / self.iters\n",
    "        return X @ w_avg\n",
    "    \n",
    "    def predict_proportion(self, X, prop):\n",
    "        w_avg = self.w_sum / self.iters\n",
    "        values = X @ w_avg\n",
    "        print(values)\n",
    "        threshold = np.quantile(values, 1-prop)\n",
    "        print(\"Threshold: \", threshold)\n",
    "        preds = np.zeros(len(values))\n",
    "        for i in range(len(preds)):\n",
    "            if values[i] >= threshold:\n",
    "                preds[i] = 1\n",
    "            else:\n",
    "                preds[i] = -1 # not having this ruined it???\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef125443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eta: 1e-05\n",
      "C: 1\n",
      "Weight: 1\n",
      "F1 score for fold 0: 0.0\n",
      "F1 score for fold 1: 0.0\n",
      "F1 score for fold 2: 0.0\n",
      "F1 score for fold 3: 0.0\n",
      "F1 score for fold 4: 0.0\n",
      "F1 score for fold 5: 0.0\n",
      "F1 score for fold 6: 0.0\n",
      "F1 score for fold 7: 0.0\n",
      "F1 score for fold 8: 0.0\n",
      "F1 score for fold 9: 0.0\n",
      "Mean validation F1 score: 0.0\n",
      "Validation F1 score stdev: 0.0\n",
      "Eta: 1e-05\n",
      "C: 1\n",
      "Weight: 2\n",
      "F1 score for fold 0: 0.0\n",
      "F1 score for fold 1: 0.0\n",
      "F1 score for fold 2: 0.0\n",
      "F1 score for fold 3: 0.0\n",
      "F1 score for fold 4: 0.0\n",
      "F1 score for fold 5: 0.0\n",
      "F1 score for fold 6: 0.0\n",
      "F1 score for fold 7: 0.0\n",
      "F1 score for fold 8: 0.0\n",
      "F1 score for fold 9: 0.0\n",
      "Mean validation F1 score: 0.0\n",
      "Validation F1 score stdev: 0.0\n",
      "Eta: 1e-05\n",
      "C: 1\n",
      "Weight: 5\n",
      "F1 score for fold 0: 0.2752412537715383\n",
      "F1 score for fold 1: 0.27395485574767053\n",
      "F1 score for fold 2: 0.2732640705583377\n",
      "F1 score for fold 3: 0.2758637882036197\n",
      "F1 score for fold 4: 0.2748217224355458\n",
      "F1 score for fold 5: 0.2755107112679557\n",
      "F1 score for fold 6: 0.2779899648019172\n",
      "F1 score for fold 7: 0.2724227577242276\n",
      "F1 score for fold 8: 0.2747102081515642\n",
      "F1 score for fold 9: 0.27498812767127395\n",
      "Mean validation F1 score: 0.2748767460333651\n",
      "Validation F1 score stdev: 0.0014393398485498447\n",
      "Eta: 1e-05\n",
      "C: 1\n",
      "Weight: 10\n",
      "F1 score for fold 0: 0.2779229417074445\n",
      "F1 score for fold 1: 0.27823606323546896\n",
      "F1 score for fold 2: 0.27637486637367853\n",
      "F1 score for fold 3: 0.2782505348229142\n",
      "F1 score for fold 4: 0.27696189274748295\n",
      "F1 score for fold 5: 0.2797684020691946\n",
      "F1 score for fold 6: 0.28025629421432485\n",
      "F1 score for fold 7: 0.2752691245117652\n",
      "F1 score for fold 8: 0.27870605851733893\n",
      "F1 score for fold 9: 0.2776230932152971\n",
      "Mean validation F1 score: 0.277936927141491\n",
      "Validation F1 score stdev: 0.001418440812717953\n",
      "Eta: 1e-05\n",
      "C: 1\n",
      "Weight: 20\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 1e-05\n",
      "C: 1\n",
      "Weight: 50\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 1e-05\n",
      "C: 10\n",
      "Weight: 1\n",
      "F1 score for fold 0: 0.0\n",
      "F1 score for fold 1: 0.0\n",
      "F1 score for fold 2: 0.0\n",
      "F1 score for fold 3: 0.0\n",
      "F1 score for fold 4: 0.0\n",
      "F1 score for fold 5: 0.0\n",
      "F1 score for fold 6: 0.0\n",
      "F1 score for fold 7: 0.0\n",
      "F1 score for fold 8: 0.0\n",
      "F1 score for fold 9: 0.0\n",
      "Mean validation F1 score: 0.0\n",
      "Validation F1 score stdev: 0.0\n",
      "Eta: 1e-05\n",
      "C: 10\n",
      "Weight: 2\n",
      "F1 score for fold 0: 0.0\n",
      "F1 score for fold 1: 0.0\n",
      "F1 score for fold 2: 0.0\n",
      "F1 score for fold 3: 0.0\n",
      "F1 score for fold 4: 0.0\n",
      "F1 score for fold 5: 0.0\n",
      "F1 score for fold 6: 0.0\n",
      "F1 score for fold 7: 0.0\n",
      "F1 score for fold 8: 0.0\n",
      "F1 score for fold 9: 0.0\n",
      "Mean validation F1 score: 0.0\n",
      "Validation F1 score stdev: 0.0\n",
      "Eta: 1e-05\n",
      "C: 10\n",
      "Weight: 5\n",
      "F1 score for fold 0: 0.2750305783679889\n",
      "F1 score for fold 1: 0.2739650872817956\n",
      "F1 score for fold 2: 0.27327364772188834\n",
      "F1 score for fold 3: 0.2759704620297375\n",
      "F1 score for fold 4: 0.2747173202206525\n",
      "F1 score for fold 5: 0.2754228855721393\n",
      "F1 score for fold 6: 0.2778819001924182\n",
      "F1 score for fold 7: 0.27247247247247247\n",
      "F1 score for fold 8: 0.27457830122766747\n",
      "F1 score for fold 9: 0.27476294127949163\n",
      "Mean validation F1 score: 0.2748075596366252\n",
      "Validation F1 score stdev: 0.0014074887585141243\n",
      "Eta: 1e-05\n",
      "C: 10\n",
      "Weight: 10\n",
      "F1 score for fold 0: 0.2779592029911496\n",
      "F1 score for fold 1: 0.27855773100688935\n",
      "F1 score for fold 2: 0.276875044348258\n",
      "F1 score for fold 3: 0.27858293075684376\n",
      "F1 score for fold 4: 0.2772483762385625\n",
      "F1 score for fold 5: 0.28065446635456565\n",
      "F1 score for fold 6: 0.28036451658835254\n",
      "F1 score for fold 7: 0.27555112598182296\n",
      "F1 score for fold 8: 0.2790290112492599\n",
      "F1 score for fold 9: 0.2774656901087961\n",
      "Mean validation F1 score: 0.27822880956245\n",
      "Validation F1 score stdev: 0.0014811457514258648\n",
      "Eta: 1e-05\n",
      "C: 10\n",
      "Weight: 20\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 1e-05\n",
      "C: 10\n",
      "Weight: 50\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 1e-05\n",
      "C: 100\n",
      "Weight: 1\n",
      "F1 score for fold 0: 0.0\n",
      "F1 score for fold 1: 0.0\n",
      "F1 score for fold 2: 0.0\n",
      "F1 score for fold 3: 0.0\n",
      "F1 score for fold 4: 0.0\n",
      "F1 score for fold 5: 0.0\n",
      "F1 score for fold 6: 0.0\n",
      "F1 score for fold 7: 0.0\n",
      "F1 score for fold 8: 0.0\n",
      "F1 score for fold 9: 0.0\n",
      "Mean validation F1 score: 0.0\n",
      "Validation F1 score stdev: 0.0\n",
      "Eta: 1e-05\n",
      "C: 100\n",
      "Weight: 2\n",
      "F1 score for fold 0: 0.0\n",
      "F1 score for fold 1: 0.0\n",
      "F1 score for fold 2: 0.0\n",
      "F1 score for fold 3: 0.0\n",
      "F1 score for fold 4: 0.0\n",
      "F1 score for fold 5: 0.0\n",
      "F1 score for fold 6: 0.0\n",
      "F1 score for fold 7: 0.0\n",
      "F1 score for fold 8: 0.0\n",
      "F1 score for fold 9: 0.0\n",
      "Mean validation F1 score: 0.0\n",
      "Validation F1 score stdev: 0.0\n",
      "Eta: 1e-05\n",
      "C: 100\n",
      "Weight: 5\n",
      "F1 score for fold 0: 0.27499126615760844\n",
      "F1 score for fold 1: 0.2738967838444278\n",
      "F1 score for fold 2: 0.27324175413228297\n",
      "F1 score for fold 3: 0.2759291593913694\n",
      "F1 score for fold 4: 0.2747348721147848\n",
      "F1 score for fold 5: 0.2754333175838659\n",
      "F1 score for fold 6: 0.277833300019988\n",
      "F1 score for fold 7: 0.2724679743795036\n",
      "F1 score for fold 8: 0.27471622801546713\n",
      "F1 score for fold 9: 0.27492182614133837\n",
      "Mean validation F1 score: 0.27481664817806367\n",
      "Validation F1 score stdev: 0.0014006850583647558\n",
      "Eta: 1e-05\n",
      "C: 100\n",
      "Weight: 10\n",
      "F1 score for fold 0: 0.2779254057132011\n",
      "F1 score for fold 1: 0.27827366821764316\n",
      "F1 score for fold 2: 0.276519553205113\n",
      "F1 score for fold 3: 0.278234037502967\n",
      "F1 score for fold 4: 0.27697354346430864\n",
      "F1 score for fold 5: 0.2803299672877258\n",
      "F1 score for fold 6: 0.2802559893417077\n",
      "F1 score for fold 7: 0.2755257398420401\n",
      "F1 score for fold 8: 0.2787286063569682\n",
      "F1 score for fold 9: 0.2774833020370326\n",
      "Mean validation F1 score: 0.2780249812968707\n",
      "Validation F1 score stdev: 0.00144264930053618\n",
      "Eta: 1e-05\n",
      "C: 100\n",
      "Weight: 20\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 1e-05\n",
      "C: 100\n",
      "Weight: 50\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eta: 0.0001\n",
      "C: 1\n",
      "Weight: 1\n",
      "F1 score for fold 0: 0.0\n",
      "F1 score for fold 1: 0.0\n",
      "F1 score for fold 2: 0.0\n",
      "F1 score for fold 3: 0.0\n",
      "F1 score for fold 4: 0.0\n",
      "F1 score for fold 5: 0.0\n",
      "F1 score for fold 6: 0.0\n",
      "F1 score for fold 7: 0.0\n",
      "F1 score for fold 8: 0.0\n",
      "F1 score for fold 9: 0.0\n",
      "Mean validation F1 score: 0.0\n",
      "Validation F1 score stdev: 0.0\n",
      "Eta: 0.0001\n",
      "C: 1\n",
      "Weight: 2\n",
      "F1 score for fold 0: 0.0\n",
      "F1 score for fold 1: 0.0\n",
      "F1 score for fold 2: 0.0\n",
      "F1 score for fold 3: 0.0\n",
      "F1 score for fold 4: 0.0\n",
      "F1 score for fold 5: 0.0\n",
      "F1 score for fold 6: 0.0\n",
      "F1 score for fold 7: 0.0\n",
      "F1 score for fold 8: 0.0\n",
      "F1 score for fold 9: 0.0\n",
      "Mean validation F1 score: 0.0\n",
      "Validation F1 score stdev: 0.0\n",
      "Eta: 0.0001\n",
      "C: 1\n",
      "Weight: 5\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 0.0001\n",
      "C: 1\n",
      "Weight: 10\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 0.0001\n",
      "C: 1\n",
      "Weight: 20\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 0.0001\n",
      "C: 1\n",
      "Weight: 50\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 0.0001\n",
      "C: 10\n",
      "Weight: 1\n",
      "F1 score for fold 0: 0.0\n",
      "F1 score for fold 1: 0.0\n",
      "F1 score for fold 2: 0.0\n",
      "F1 score for fold 3: 0.0\n",
      "F1 score for fold 4: 0.0\n",
      "F1 score for fold 5: 0.0\n",
      "F1 score for fold 6: 0.0\n",
      "F1 score for fold 7: 0.0\n",
      "F1 score for fold 8: 0.0\n",
      "F1 score for fold 9: 0.0\n",
      "Mean validation F1 score: 0.0\n",
      "Validation F1 score stdev: 0.0\n",
      "Eta: 0.0001\n",
      "C: 10\n",
      "Weight: 2\n",
      "F1 score for fold 0: 0.0\n",
      "F1 score for fold 1: 0.0\n",
      "F1 score for fold 2: 0.0\n",
      "F1 score for fold 3: 0.0\n",
      "F1 score for fold 4: 0.0\n",
      "F1 score for fold 5: 0.0\n",
      "F1 score for fold 6: 0.0\n",
      "F1 score for fold 7: 0.0\n",
      "F1 score for fold 8: 0.0\n",
      "F1 score for fold 9: 0.0\n",
      "Mean validation F1 score: 0.0\n",
      "Validation F1 score stdev: 0.0\n",
      "Eta: 0.0001\n",
      "C: 10\n",
      "Weight: 5\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 0.0001\n",
      "C: 10\n",
      "Weight: 10\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 0.0001\n",
      "C: 10\n",
      "Weight: 20\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 0.0001\n",
      "C: 10\n",
      "Weight: 50\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 0.0001\n",
      "C: 100\n",
      "Weight: 1\n",
      "F1 score for fold 0: 0.0\n",
      "F1 score for fold 1: 0.0\n",
      "F1 score for fold 2: 0.0\n",
      "F1 score for fold 3: 0.0\n",
      "F1 score for fold 4: 0.0\n",
      "F1 score for fold 5: 0.0\n",
      "F1 score for fold 6: 0.0\n",
      "F1 score for fold 7: 0.0\n",
      "F1 score for fold 8: 0.0\n",
      "F1 score for fold 9: 0.0\n",
      "Mean validation F1 score: 0.0\n",
      "Validation F1 score stdev: 0.0\n",
      "Eta: 0.0001\n",
      "C: 100\n",
      "Weight: 2\n",
      "F1 score for fold 0: 0.0\n",
      "F1 score for fold 1: 0.0\n",
      "F1 score for fold 2: 0.0\n",
      "F1 score for fold 3: 0.0\n",
      "F1 score for fold 4: 0.0\n",
      "F1 score for fold 5: 0.0\n",
      "F1 score for fold 6: 0.0\n",
      "F1 score for fold 7: 0.0\n",
      "F1 score for fold 8: 0.0\n",
      "F1 score for fold 9: 0.0\n",
      "Mean validation F1 score: 0.0\n",
      "Validation F1 score stdev: 0.0\n",
      "Eta: 0.0001\n",
      "C: 100\n",
      "Weight: 5\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 0.0001\n",
      "C: 100\n",
      "Weight: 10\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 0.0001\n",
      "C: 100\n",
      "Weight: 20\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 0.0001\n",
      "C: 100\n",
      "Weight: 50\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eta: 0.001\n",
      "C: 1\n",
      "Weight: 1\n",
      "F1 score for fold 0: 0.0\n",
      "F1 score for fold 1: 0.0\n",
      "F1 score for fold 2: 0.0\n",
      "F1 score for fold 3: 0.0\n",
      "F1 score for fold 4: 0.0\n",
      "F1 score for fold 5: 0.0\n",
      "F1 score for fold 6: 0.0\n",
      "F1 score for fold 7: 0.0\n",
      "F1 score for fold 8: 0.0\n",
      "F1 score for fold 9: 0.0\n",
      "Mean validation F1 score: 0.0\n",
      "Validation F1 score stdev: 0.0\n",
      "Eta: 0.001\n",
      "C: 1\n",
      "Weight: 2\n",
      "F1 score for fold 0: 0.0\n",
      "F1 score for fold 1: 0.0\n",
      "F1 score for fold 2: 0.0\n",
      "F1 score for fold 3: 0.0\n",
      "F1 score for fold 4: 0.0\n",
      "F1 score for fold 5: 0.0\n",
      "F1 score for fold 6: 0.0\n",
      "F1 score for fold 7: 0.0\n",
      "F1 score for fold 8: 0.0\n",
      "F1 score for fold 9: 0.0\n",
      "Mean validation F1 score: 0.0\n",
      "Validation F1 score stdev: 0.0\n",
      "Eta: 0.001\n",
      "C: 1\n",
      "Weight: 5\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 0.001\n",
      "C: 1\n",
      "Weight: 10\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 0.001\n",
      "C: 1\n",
      "Weight: 20\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 0.001\n",
      "C: 1\n",
      "Weight: 50\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 0.001\n",
      "C: 10\n",
      "Weight: 1\n",
      "F1 score for fold 0: 0.0\n",
      "F1 score for fold 1: 0.0\n",
      "F1 score for fold 2: 0.0\n",
      "F1 score for fold 3: 0.0\n",
      "F1 score for fold 4: 0.0\n",
      "F1 score for fold 5: 0.0\n",
      "F1 score for fold 6: 0.0\n",
      "F1 score for fold 7: 0.0\n",
      "F1 score for fold 8: 0.0\n",
      "F1 score for fold 9: 0.0\n",
      "Mean validation F1 score: 0.0\n",
      "Validation F1 score stdev: 0.0\n",
      "Eta: 0.001\n",
      "C: 10\n",
      "Weight: 2\n",
      "F1 score for fold 0: 0.0\n",
      "F1 score for fold 1: 0.0\n",
      "F1 score for fold 2: 0.0\n",
      "F1 score for fold 3: 0.0\n",
      "F1 score for fold 4: 0.0\n",
      "F1 score for fold 5: 0.0\n",
      "F1 score for fold 6: 0.0\n",
      "F1 score for fold 7: 0.0\n",
      "F1 score for fold 8: 0.0\n",
      "F1 score for fold 9: 0.0\n",
      "Mean validation F1 score: 0.0\n",
      "Validation F1 score stdev: 0.0\n",
      "Eta: 0.001\n",
      "C: 10\n",
      "Weight: 5\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 0.001\n",
      "C: 10\n",
      "Weight: 10\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 0.001\n",
      "C: 10\n",
      "Weight: 20\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 0.001\n",
      "C: 10\n",
      "Weight: 50\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 0.001\n",
      "C: 100\n",
      "Weight: 1\n",
      "F1 score for fold 0: 0.0\n",
      "F1 score for fold 1: 0.0\n",
      "F1 score for fold 2: 0.0\n",
      "F1 score for fold 3: 0.0\n",
      "F1 score for fold 4: 0.0\n",
      "F1 score for fold 5: 0.0\n",
      "F1 score for fold 6: 0.0\n",
      "F1 score for fold 7: 0.0\n",
      "F1 score for fold 8: 0.0\n",
      "F1 score for fold 9: 0.0\n",
      "Mean validation F1 score: 0.0\n",
      "Validation F1 score stdev: 0.0\n",
      "Eta: 0.001\n",
      "C: 100\n",
      "Weight: 2\n",
      "F1 score for fold 0: 0.0\n",
      "F1 score for fold 1: 0.0\n",
      "F1 score for fold 2: 0.0\n",
      "F1 score for fold 3: 0.0\n",
      "F1 score for fold 4: 0.0\n",
      "F1 score for fold 5: 0.0\n",
      "F1 score for fold 6: 0.0\n",
      "F1 score for fold 7: 0.0\n",
      "F1 score for fold 8: 0.0\n",
      "F1 score for fold 9: 0.0\n",
      "Mean validation F1 score: 0.0\n",
      "Validation F1 score stdev: 0.0\n",
      "Eta: 0.001\n",
      "C: 100\n",
      "Weight: 5\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 0.001\n",
      "C: 100\n",
      "Weight: 10\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 0.001\n",
      "C: 100\n",
      "Weight: 20\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Eta: 0.001\n",
      "C: 100\n",
      "Weight: 50\n",
      "F1 score for fold 0: 0.28262628078374974\n",
      "F1 score for fold 1: 0.2822725638259619\n",
      "F1 score for fold 2: 0.27910746853398777\n",
      "F1 score for fold 3: 0.2811136598749607\n",
      "F1 score for fold 4: 0.2805786146543385\n",
      "F1 score for fold 5: 0.2840143691064212\n",
      "F1 score for fold 6: 0.2829671564002336\n",
      "F1 score for fold 7: 0.2783709510294184\n",
      "F1 score for fold 8: 0.2830442986791266\n",
      "F1 score for fold 9: 0.28096534041069704\n",
      "Mean validation F1 score: 0.28150607032988956\n",
      "Validation F1 score stdev: 0.0017182455556877898\n",
      "Best eta value: 0.001\n",
      "Best C value: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test precision: 0.1637601727287826\n",
      "Test recall: 1.0\n",
      "Test F1 score: 0.28143285286142433\n",
      "Test AUPRC score: 0.1637601727287826\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "eta_vals = [0.00001, 0.0001, 0.001]\n",
    "C_vals = [1, 10, 100]\n",
    "weights = [1, 2, 5, 10, 20, 50]\n",
    "best_score = 0\n",
    "best_eta, best_c, best_weight = (0, 0, 0)\n",
    "\n",
    "(_, num_features) = X_train.shape\n",
    "proportion = len(y_train[y_train == 1])/len(y_train)\n",
    "\n",
    "for eta_val in eta_vals:\n",
    "    for c_val in C_vals:\n",
    "        for w in weights:\n",
    "\n",
    "            # instantiate svm object\n",
    "            svm = MyWeightedSVM(num_features, 100000, eta_val, c_val, w)\n",
    "\n",
    "            # call to your CV function to compute error rates for each fold\n",
    "            #cv_scores = my_cross_val_imbalanced(svm, 'f1', proportion, X_train, y_train, k=10)\n",
    "            cv_scores = my_cross_val_imbalanced(svm, 'f1', None, X_train, y_train, k=10)\n",
    "\n",
    "            # print error rates from CV\n",
    "            print(\"Eta: \" + str(eta_val))\n",
    "            print(\"C: \" + str(c_val))\n",
    "            print(\"Weight: \" + str(w))\n",
    "            for i in range(10):\n",
    "                print(\"F1 score for fold \" + str(i) + \": \" + str(cv_scores[i]))\n",
    "            mean_score = sum(cv_scores)/len(cv_scores)\n",
    "            print(\"Mean validation F1 score: \" + str(mean_score))\n",
    "            print(\"Validation F1 score stdev: \" + str(np.std(cv_scores)))\n",
    "            if mean_score >= best_score:\n",
    "                best_score = mean_score\n",
    "                best_eta, best_c, best_weight = (eta_val, c_val, w)\n",
    "\n",
    "# instantiate svm object for best value of eta and C\n",
    "print(\"Best eta value: \" + str(best_eta))\n",
    "print(\"Best C value: \" + str(best_c))\n",
    "best_svm = MyWeightedSVM(num_features, 100000, best_eta, best_c, best_weight)\n",
    "\n",
    "# fit model using all training data\n",
    "best_svm.fit(X_train, y_train)\n",
    "\n",
    "# predict on test data\n",
    "#y_preds = best_svm.predict_proportion(X_test, proportion)\n",
    "y_preds = best_svm.predict(X_test)\n",
    "\n",
    "# compute F1 score on test data\n",
    "(precision, recall, f1) = precision_recall_f1(y_preds, y_test)\n",
    "auprc = sklearn.metrics.average_precision_score(y_test, y_preds)\n",
    "\n",
    "print(\"Test precision: \" + str(precision))\n",
    "print(\"Test recall: \" + str(recall))\n",
    "print(\"Test F1 score: \" + str(f1))\n",
    "print(\"Test AUPRC score: \" + str(auprc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52a0d095",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyWeightedSVM:\n",
    "\n",
    "    def __init__(self, d, max_iters, eta_val, c, w1):\n",
    "        self.w = np.zeros(d)\n",
    "        self.w_old = np.random.uniform(-0.01, 0.01, d)\n",
    "        self.w_sum = np.zeros(d)\n",
    "        self.w_sum += self.w_old\n",
    "        self.max_iters = max_iters\n",
    "        self.eta_val = eta_val\n",
    "        self.c = c\n",
    "        self.iters = 0\n",
    "        self.losses = []\n",
    "        self.gradient_magnitudes = []\n",
    "        self.w1 = w1\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        (n, d) = X.shape\n",
    "        while self.iters < self.max_iters:\n",
    "            i = np.random.randint(n)\n",
    "            # compute loss; maybe modify for weighted?\n",
    "            class_weight = self.w1 if y[i] == 1 else 1\n",
    "            loss = (1/2)*np.linalg.norm(self.w_old)**2 + self.c*class_weight*max(0, 1 - y[i]*(self.w_old @ X[i, :]))\n",
    "            self.losses.append(loss)\n",
    "            gradient_magnitude = 0\n",
    "            for j in range(d):\n",
    "                if y[i]*(self.w_old @ X[i, :]) < 1:\n",
    "                    self.w[j] = self.w_old[j] - self.eta_val*(self.w_old[j] - self.c*class_weight*y[i]*X[i,j])\n",
    "                    gradient_magnitude += (self.w_old[j] - self.c*class_weight*y[i]*X[i,j])**2\n",
    "                else:\n",
    "                    self.w[j] = self.w_old[j] - self.eta_val*(self.w_old[j])\n",
    "                    gradient_magnitude += (self.w_old[j])**2\n",
    "                self.w_old[j] = self.w[j]\n",
    "            self.gradient_magnitudes.append(gradient_magnitude)\n",
    "            self.w_sum += self.w\n",
    "            self.iters += 1\n",
    "            if np.average(self.gradient_magnitudes[-10:]) < 1e-6:\n",
    "                break\n",
    "\n",
    "    def predict(self, X):\n",
    "        w_avg = self.w_sum / self.iters\n",
    "        return np.sign(X @ w_avg)\n",
    "    \n",
    "    def predict_values(self, X):\n",
    "        w_avg = self.w_sum / self.iters\n",
    "        return X @ w_avg\n",
    "    \n",
    "    def predict_proportion(self, X, prop):\n",
    "        w_avg = self.w_sum / self.iters\n",
    "        values = X @ w_avg\n",
    "        print(values)\n",
    "        threshold = np.quantile(values, 1-prop)\n",
    "        print(\"Threshold: \", threshold)\n",
    "        preds = np.zeros(len(values))\n",
    "        for i in range(len(preds)):\n",
    "            if values[i] >= threshold:\n",
    "                preds[i] = 1\n",
    "            else:\n",
    "                preds[i] = -1 # not having this ruined it???\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb71df83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -340.78340826 -5714.30722881 -4769.92171392 ...  -401.37298046\n",
      " -4344.35603474 -3177.98718613]\n",
      "Threshold:  -1877.295806877316\n",
      "[-5506.79420643 -4705.89122078 -4167.95341576 ...  -342.3145942\n",
      " -2716.95301058 -4002.39715317]\n",
      "Threshold:  -454.35452427253745\n",
      "[-4454.05105841 -4294.37879242 -3645.94770465 ... -5628.9812671\n",
      " -4676.88084326  -371.92336495]\n",
      "Threshold:  -2063.964574860334\n",
      "[-5070.71454349 -4688.22434776 -5454.93369261 ... -3950.03884792\n",
      " -6523.75837462 -4437.27482084]\n",
      "Threshold:  -1880.3021521865212\n",
      "[-5609.2593175  -6107.42485473 -3291.99807446 ... -3834.9898055\n",
      "  -339.80488442 -3807.74949837]\n",
      "Threshold:  -456.9874443138388\n",
      "[-6563.15441277 -4730.08667061  -374.76596402 ... -3865.76554071\n",
      " -3400.70999606 -6523.80675297]\n",
      "Threshold:  -2125.3090884189382\n",
      "[-4145.6048458  -3977.66453598 -3895.26116103 ... -4085.69116899\n",
      " -3516.75603956 -4494.16971387]\n",
      "Threshold:  -447.0706700093037\n",
      "[-5199.63282856 -4880.06379703 -7212.18897861 ... -5567.31389467\n",
      " -3472.95519515 -3884.77380078]\n",
      "Threshold:  -452.89016038093115\n",
      "[-4166.24826033 -4767.08216391 -7973.31682899 ... -5450.44818472\n",
      " -4902.7286967   -438.02598239]\n",
      "Threshold:  -450.60956662633726\n",
      "[-3673.69014461 -5116.88629116 -2621.89155607 ... -5356.18639459\n",
      " -3398.77059713 -4013.05822305]\n",
      "Threshold:  -452.76206622096305\n",
      "Eta: 1e-05\n",
      "C: 1\n",
      "Weight: 1\n",
      "F1 score for fold 0: 0.1797752808988764\n",
      "F1 score for fold 1: 0.17988996092815562\n",
      "F1 score for fold 2: 0.16952961952159254\n",
      "F1 score for fold 3: 0.16305651027096155\n",
      "F1 score for fold 4: 0.16821382842509602\n",
      "F1 score for fold 5: 0.1797377830750894\n",
      "F1 score for fold 6: 0.16959949040528702\n",
      "F1 score for fold 7: 0.17316504542165767\n",
      "F1 score for fold 8: 0.1837433325372184\n",
      "F1 score for fold 9: 0.17031824724132416\n",
      "Mean validation F1 score: 0.17370290987252593\n",
      "Validation F1 score stdev: 0.006339231460420875\n",
      "[ -106.23536971 -1310.31678813 -2147.05916239 ... -1546.4262145\n",
      " -2369.20565861 -1454.99448724]\n",
      "Threshold:  -603.8465368957457\n",
      "[-1409.37950481 -2570.49690906 -1601.58385119 ...  -303.62524569\n",
      " -1398.70098412  -333.34819837]\n",
      "Threshold:  -603.7501334923462\n",
      "[-1047.32188086 -1387.89402731  -519.54992973 ... -1518.1036356\n",
      "  -918.93057119  -829.75623328]\n",
      "Threshold:  -596.4610173975618\n",
      "[-1047.63330978 -2365.46719103  -971.68223257 ... -1501.48063108\n",
      " -1153.94308373 -2551.72885023]\n",
      "Threshold:  -600.6094406395596\n",
      "[-1333.18713774 -1224.19390448 -2059.91520642 ... -2319.9841789\n",
      "  -217.64752002 -1699.0213699 ]\n",
      "Threshold:  -603.6515311323305\n",
      "[-2583.59772796 -2273.49691029  -980.62203037 ... -1523.27393652\n",
      "  -549.97342271 -2372.41621519]\n",
      "Threshold:  -602.2919131656101\n",
      "[-1821.64456683  -452.04131753  -696.74373015 ... -1409.12083199\n",
      " -2289.69175473 -2189.76320799]\n",
      "Threshold:  -601.2459755921524\n",
      "[ -794.38205918  -740.37501772 -2637.87595818 ... -1390.01229649\n",
      " -1252.68805546 -2131.80028293]\n",
      "Threshold:  -604.6230356486097\n",
      "[-1797.97151149 -2048.37305489  -622.72622586 ... -1272.61252036\n",
      "  -734.72302355 -2150.35505814]\n",
      "Threshold:  -599.1399963333764\n",
      "[-2152.74118541 -1133.06721742 -1162.5643972  ... -1695.89856813\n",
      " -1783.44814658  -994.01110506]\n",
      "Threshold:  -607.215489806083\n",
      "Eta: 1e-05\n",
      "C: 1\n",
      "Weight: 2\n",
      "F1 score for fold 0: 0.17244401944378038\n",
      "F1 score for fold 1: 0.1704808229008851\n",
      "F1 score for fold 2: 0.16407127949911707\n",
      "F1 score for fold 3: 0.16193749500439614\n",
      "F1 score for fold 4: 0.16757362355953906\n",
      "F1 score for fold 5: 0.1619388160508542\n",
      "F1 score for fold 6: 0.16896249701409347\n",
      "F1 score for fold 7: 0.16480424471420532\n",
      "F1 score for fold 8: 0.1737122840538174\n",
      "F1 score for fold 9: 0.16312170158324005\n",
      "Mean validation F1 score: 0.1669046783823928\n",
      "Validation F1 score stdev: 0.004130160927321148\n",
      "[  964.46782096 17530.41630452 11361.29814132 ... -3282.410925\n",
      "  9061.56612748  7487.38101516]\n",
      "Threshold:  17634.235583180398\n",
      "[16437.30599926  9784.07300674 10777.95451256 ...   362.95871928\n",
      "  5918.44155803 14103.57149343]\n",
      "Threshold:  17648.96959316688\n",
      "[13583.74407941 11926.10916609 12177.36717962 ... 16554.13405021\n",
      " 14821.26894688 -1166.93406536]\n",
      "Threshold:  17697.660460075225\n",
      "[15912.61973741 10359.06053389 17600.61425963 ... 10267.87925457\n",
      " 21081.19595598  8828.12596022]\n",
      "Threshold:  17723.928907758196\n",
      "[17064.13108088 19278.08371892  6041.29103689 ...  7272.21017309\n",
      "   619.6954093   9114.39525045]\n",
      "Threshold:  17566.484930910898\n",
      "[16764.18457929 10813.11110751 -1622.02203178 ...  9879.43508345\n",
      " 11148.39802035 17286.70384463]\n",
      "Threshold:  17577.030457924175\n",
      "[ 9999.962136   13642.82323648 12577.03198209 ... 11066.50590798\n",
      "  6166.16131005 10171.40905809]\n",
      "Threshold:  17696.501475521465\n",
      "[17186.06833002 16153.65516042 19057.26616515 ... 16719.90540101\n",
      "  9233.8628613   8056.50555331]\n",
      "Threshold:  17644.76556003162\n",
      "[10161.19082429 11646.41064967 28224.25980903 ... 16651.94335802\n",
      " 16250.44537286 -5030.70070526]\n",
      "Threshold:  17591.66513853348\n",
      "[ 7183.94827469 15817.19128083  6300.15510381 ... 14976.11365436\n",
      "  7298.27472473 12080.86925858]\n",
      "Threshold:  17566.643349657217\n",
      "Eta: 1e-05\n",
      "C: 1\n",
      "Weight: 5\n",
      "F1 score for fold 0: 0.19794405928759265\n",
      "F1 score for fold 1: 0.19535922175265127\n",
      "F1 score for fold 2: 0.19714239845882164\n",
      "F1 score for fold 3: 0.1996642954200304\n",
      "F1 score for fold 4: 0.20422535211267606\n",
      "F1 score for fold 5: 0.2013508144616607\n",
      "F1 score for fold 6: 0.20160840831276378\n",
      "F1 score for fold 7: 0.2030709864136988\n",
      "F1 score for fold 8: 0.1971180638484197\n",
      "F1 score for fold 9: 0.20502158963697426\n",
      "Mean validation F1 score: 0.20025051897052895\n",
      "Validation F1 score stdev: 0.003140586808938396\n",
      "[ 3261.40935056 55975.93211199 41755.36782675 ... -2893.53277797\n",
      " 36070.4432242  27652.51434142]\n",
      "Threshold:  56137.79858947721\n",
      "[53242.86449443 38888.91138038 37761.00796521 ...  2396.93198905\n",
      " 22893.93299212 42047.70048858]\n",
      "Threshold:  56178.50538906651\n",
      "[43511.71943012 40201.79672656 37288.29521039 ... 53996.3552101\n",
      " 46509.80023328   171.50815105]\n",
      "Threshold:  56264.11264040351\n",
      "[50207.64400847 39706.66813922 54742.42854535 ... 35887.04887894\n",
      " 65564.31598386 36064.67602955]\n",
      "Threshold:  56367.28865808937\n",
      "[54741.63060675 60607.40482818 26055.30681964 ... 30615.46655539\n",
      "  2767.8045074  33389.9391842 ]\n",
      "Threshold:  55875.89939414293\n",
      "[59031.0710364  40683.65370597  -484.10605052 ... 34847.94431399\n",
      " 34413.22414734 59731.61340551]\n",
      "Threshold:  56188.01560779307\n",
      "[36393.16704836 41231.85019926 39232.06075878 ... 37788.59270732\n",
      " 27321.27585438 38425.64762865]\n",
      "Threshold:  56337.788561477006\n",
      "[52799.8814384  49645.73363857 65905.89028435 ... 53938.43287784\n",
      " 31842.10688368 32144.49183877]\n",
      "Threshold:  56214.51622400716\n",
      "[36813.56479005 42097.70135771 83955.74252711 ... 53299.61057917\n",
      " 49863.74558531 -5439.72780862]\n",
      "Threshold:  56055.48157672061\n",
      "[29666.0558751  50266.21697292 23038.70956817 ... 50236.63955731\n",
      " 28474.74670738 38953.52736941]\n",
      "Threshold:  56041.49469720807\n",
      "Eta: 1e-05\n",
      "C: 1\n",
      "Weight: 10\n",
      "F1 score for fold 0: 0.1989003107817356\n",
      "F1 score for fold 1: 0.1966350370783829\n",
      "F1 score for fold 2: 0.19955048964520788\n",
      "F1 score for fold 3: 0.2007833106865958\n",
      "F1 score for fold 4: 0.2047055057618438\n",
      "F1 score for fold 5: 0.2034167659912594\n",
      "F1 score for fold 6: 0.2027231467473525\n",
      "F1 score for fold 7: 0.20371412492965674\n",
      "F1 score for fold 8: 0.19584427991401962\n",
      "F1 score for fold 9: 0.20422197345274265\n",
      "Mean validation F1 score: 0.2010494944988797\n",
      "Validation F1 score stdev: 0.003040640323728027\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m svm \u001b[38;5;241m=\u001b[39m MyWeightedSVM(num_features, \u001b[38;5;241m1000000\u001b[39m, eta_val, c_val, w)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# call to your CV function to compute error rates for each fold\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m cv_scores \u001b[38;5;241m=\u001b[39m \u001b[43mmy_cross_val_imbalanced\u001b[49m\u001b[43m(\u001b[49m\u001b[43msvm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproportion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#cv_scores = my_cross_val_imbalanced(svm, 'f1', None, X_train, y_train, k=10)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# print error rates from CV\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEta: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(eta_val))\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mmy_cross_val_imbalanced\u001b[1;34m(model, metric, proportion, X, y, k)\u001b[0m\n\u001b[0;32m      9\u001b[0m train_set \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdelete(X, [j \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mround\u001b[39m(i\u001b[38;5;241m*\u001b[39mn\u001b[38;5;241m/\u001b[39mk), \u001b[38;5;28mround\u001b[39m((i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mn\u001b[38;5;241m/\u001b[39mk))], \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     10\u001b[0m train_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdelete(y, [j \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mround\u001b[39m(i\u001b[38;5;241m*\u001b[39mn\u001b[38;5;241m/\u001b[39mk), \u001b[38;5;28mround\u001b[39m((i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mn\u001b[38;5;241m/\u001b[39mk))], \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m proportion \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     y_preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(val_set)\n",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36mMyWeightedSVM.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# compute loss; maybe modify for weighted?\u001b[39;00m\n\u001b[0;32m     21\u001b[0m class_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw1 \u001b[38;5;28;01mif\u001b[39;00m y[i] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 22\u001b[0m loss \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw_old\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc\u001b[38;5;241m*\u001b[39mclass_weight\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m y[i]\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_old \u001b[38;5;241m@\u001b[39m X[i, :]))\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m     24\u001b[0m gradient_magnitude \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py:2530\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[0;32m   2528\u001b[0m     sqnorm \u001b[38;5;241m=\u001b[39m dot(x\u001b[38;5;241m.\u001b[39mreal, x\u001b[38;5;241m.\u001b[39mreal) \u001b[38;5;241m+\u001b[39m dot(x\u001b[38;5;241m.\u001b[39mimag, x\u001b[38;5;241m.\u001b[39mimag)\n\u001b[0;32m   2529\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2530\u001b[0m     sqnorm \u001b[38;5;241m=\u001b[39m \u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2531\u001b[0m ret \u001b[38;5;241m=\u001b[39m sqrt(sqnorm)\n\u001b[0;32m   2532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keepdims:\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#SVM with proportion strategy\n",
    "eta_vals = [0.00001, 0.0001, 0.001]\n",
    "C_vals = [1, 10, 100]\n",
    "weights = [1, 2, 5, 10, 20, 50]\n",
    "best_score = 0\n",
    "best_eta, best_c, best_weight = (0, 0, 0)\n",
    "\n",
    "(_, num_features) = X_train.shape\n",
    "proportion = len(y_train[y_train == 1])/len(y_train)\n",
    "\n",
    "for eta_val in eta_vals:\n",
    "    for c_val in C_vals:\n",
    "        for w in weights:\n",
    "\n",
    "            # instantiate svm object\n",
    "            svm = MyWeightedSVM(num_features, 1000000, eta_val, c_val, w)\n",
    "\n",
    "            # call to your CV function to compute error rates for each fold\n",
    "            cv_scores = my_cross_val_imbalanced(svm, 'f1', proportion, X_train, y_train, k=10)\n",
    "            #cv_scores = my_cross_val_imbalanced(svm, 'f1', None, X_train, y_train, k=10)\n",
    "\n",
    "            # print error rates from CV\n",
    "            print(\"Eta: \" + str(eta_val))\n",
    "            print(\"C: \" + str(c_val))\n",
    "            print(\"Weight: \" + str(w))\n",
    "            for i in range(10):\n",
    "                print(\"F1 score for fold \" + str(i) + \": \" + str(cv_scores[i]))\n",
    "            mean_score = sum(cv_scores)/len(cv_scores)\n",
    "            print(\"Mean validation F1 score: \" + str(mean_score))\n",
    "            print(\"Validation F1 score stdev: \" + str(np.std(cv_scores)))\n",
    "            if mean_score >= best_score:\n",
    "                best_score = mean_score\n",
    "                best_eta, best_c, best_weight = (eta_val, c_val, w)\n",
    "\n",
    "# instantiate svm object for best value of eta and C\n",
    "print(\"Best eta value: \" + str(best_eta))\n",
    "print(\"Best C value: \" + str(best_c))\n",
    "best_svm = MyWeightedSVM(num_features, 1000000, best_eta, best_c, best_weight)\n",
    "\n",
    "# fit model using all training data\n",
    "best_svm.fit(X_train, y_train)\n",
    "\n",
    "# predict on test data\n",
    "y_preds = best_svm.predict_proportion(X_test, proportion)\n",
    "#y_preds = best_svm.predict(X_test)\n",
    "y_values = best_svm.predict_values(X_test)\n",
    "\n",
    "# compute F1 score on test data\n",
    "(precision, recall, f1) = precision_recall_f1(y_preds, y_test)\n",
    "auprc = sklearn.metrics.average_precision_score(y_test, y_values)\n",
    "\n",
    "print(\"Test precision: \" + str(precision))\n",
    "print(\"Test recall: \" + str(recall))\n",
    "print(\"Test F1 score: \" + str(f1))\n",
    "print(\"Test AUPRC score: \" + str(auprc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c5737ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best eta value: 1e-05\n",
      "Best C value: 10\n",
      "Best weight: 10\n",
      "[481841.85743339 486435.80520021 321143.54598108 ... 456453.68223765\n",
      " 330605.62272964 306240.02100185]\n",
      "Threshold:  557386.6855402336\n",
      "Test precision: 0.2041023241304009\n",
      "Test recall: 0.20416601653924168\n",
      "Test F1 score: 0.20413416536661466\n",
      "Test AUPRC score: 0.18683279665644137\n"
     ]
    }
   ],
   "source": [
    "# instantiate svm object for best value of eta and C\n",
    "print(\"Best eta value: \" + str(best_eta))\n",
    "print(\"Best C value: \" + str(best_c))\n",
    "print(\"Best weight: \" + str(best_weight))\n",
    "best_svm = MyWeightedSVM(num_features, 1000000, best_eta, best_c, best_weight)\n",
    "\n",
    "# fit model using all training data\n",
    "best_svm.fit(X_train, y_train)\n",
    "\n",
    "# predict on test data\n",
    "y_preds = best_svm.predict_proportion(X_test, proportion)\n",
    "#y_preds = best_svm.predict(X_test)\n",
    "y_values = best_svm.predict_values(X_test)\n",
    "\n",
    "# compute F1 score on test data\n",
    "(precision, recall, f1) = precision_recall_f1(y_preds, y_test)\n",
    "auprc = sklearn.metrics.average_precision_score(y_test, y_values)\n",
    "\n",
    "print(\"Test precision: \" + str(precision))\n",
    "print(\"Test recall: \" + str(recall))\n",
    "print(\"Test F1 score: \" + str(f1))\n",
    "print(\"Test AUPRC score: \" + str(auprc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c807011e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display = sklearn.metrics.PrecisionRecallDisplay.from_predictions(y_test, y_values, name=\"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f429c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best weight: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Best weight: \" + str(best_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18494ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.616746128524103e-06\n"
     ]
    }
   ],
   "source": [
    "print(proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e027cb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62601"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train[y_train == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725140ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
